{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d575e93a-e6e2-4384-819b-1c4bc3d604c7",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Serif; font-size: 35px; font-style: normal; letter-spacing: 3px; background-color: #f6f6f6; color: #0D0D0F; border-radius: 100px 100px; text-align: center;\"> 2.1 WEB SCRAPING TO OBTAIN DATA </h2>\n",
    "\n",
    "This file contains the code for scraping Steam reviews for the game [**Black Myth: Wukong**](https://steamcommunity.com/app/2358720/reviews/). It is the **Section 2.1** of the main file `end-to-end-sentiment-analysis.ipynb`.\n",
    "\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760e2f4-d0b6-4f0f-8d35-671888b859f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules for Web Scraping\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eab414-52af-4cd6-9ba4-f68ce077f722",
   "metadata": {},
   "source": [
    "# Information of the Game & Steam Review Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ddcd3-6931-4b79-9894-57b2d18cd474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the webpage we are going to scrape\n",
    "\n",
    "# Game id of the game we chose\n",
    "game_id = 2358720 # Change if want to scrape reviews for other games\n",
    "\n",
    "# Set url template\n",
    "url_template = \"https://steamcommunity.com/app/{}/reviews/?p=1&browsefilter=mostrecent&filterLanguage=english\"\n",
    "\n",
    "# Get the url we want\n",
    "url = url_template.format(game_id)\n",
    "\n",
    "# Print the url to check if it is what we want\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2cf46-f1fd-42cb-9af2-f9b0e8fb81d9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2b1c9-d4a7-4d01-b751-082a5670352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS FIRST TO SETUP\n",
    "\n",
    "# Set up and open the relevant browser\n",
    "# Set up EdgeOptions\n",
    "options = Options()\n",
    "options.use_chromium = True  # Ensures the use of Chromium-based Edge\n",
    "language = \"en-US\"\n",
    "options.add_argument(f\"--lang={language}\")\n",
    "\n",
    "# Path to the msedgedriver executable\n",
    "webdriver_path = \"___.exe\" # Insert your own webdriver path into '___'\n",
    "\n",
    "# Set up the service for Edge\n",
    "service = Service(executable_path=webdriver_path)\n",
    "\n",
    "# Initialize the Edge driver with the options and service\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "\n",
    "# Maximize the window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Navigate to our URL\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed9e08-7f78-42d9-9fb1-eb5f445d7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS AFTER FINISH SETTING UP\n",
    "\n",
    "# Close the browser after we are done\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ab6b1-7482-4f9b-9528-5e41608bfb6f",
   "metadata": {},
   "source": [
    "# Scrape Reviews (Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f59f3-ed7b-4e3e-8ab3-7be378967b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FUNCTIONS TO SCRAPE\n",
    "\n",
    "# Define functions to scrape data (reviews) from the review page\n",
    "# Define a function to get the current scroll position\n",
    "def get_current_scroll_position(driver):\n",
    "    '''\n",
    "    Get the current scroll position.\n",
    "    '''\n",
    "    return driver.execute_script(\"return window.pageYOffset;\")\n",
    "\n",
    "# Define a function to scroll the review page to the bottom\n",
    "def scroll_to_bottom(driver):\n",
    "    '''\n",
    "    Scroll the review page to the bottom.\n",
    "    '''\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "# Define a function to get the user ID associated with the reviews\n",
    "def get_steam_id(card):\n",
    "    '''\n",
    "    Get the User ID associated with each review.\n",
    "    '''\n",
    "    profile_url = card.find_element(By.XPATH, './/div[@class=\"apphub_friend_block\"]/div/a[2]').get_attribute('href')\n",
    "    steam_id = profile_url.split('/')[-2]\n",
    "    return steam_id\n",
    "\n",
    "# Define a function to scrape the data (review)\n",
    "def scrape_review_data(card):\n",
    "    '''\n",
    "    Scrape the data (review) from the review page.\n",
    "    '''\n",
    "    # Find the date posted of reviews\n",
    "    date_posted_element = card.find_element(By.XPATH, './/div[@class=\"apphub_CardTextContent\"]/div[@class=\"date_posted\"]')\n",
    "    date_posted = date_posted_element.text.strip()\n",
    "\n",
    "    # Clean the data to obtain the reviews\n",
    "    card_text_content_element = card.find_element(By.CLASS_NAME, \"apphub_CardTextContent\")\n",
    "    review_content = card_text_content_element.text.strip()\n",
    "    review_content = review_content.replace(date_posted, \"\")\n",
    "    review_content = review_content.replace(\"\\n\", \"\")\n",
    "\n",
    "    # Find the length of reviews\n",
    "    review_length = len(review_content.replace(\" \", \"\"))\n",
    "\n",
    "    # Thumbs up (Recommended) OR thumbs down (NOT Recommended)\n",
    "    thumb_text = card.find_element(By.XPATH, './/div[@class=\"reviewInfo\"]/div[2]').text\n",
    "\n",
    "    # Number of hours played\n",
    "    play_hours = card.find_element(By.XPATH, './/div[@class=\"reviewInfo\"]/div[3]').text\n",
    "\n",
    "    return review_content, thumb_text, review_length, play_hours, date_posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58087b43-860e-42f1-a812-53d93cd65f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SCRAPING\n",
    "\n",
    "# Retrieve reviews from the review page\n",
    "# Initialize and set variables\n",
    "reviews = []\n",
    "steam_ids_set = set() # Avoid duplicates by checking if reviews have the same IDs\n",
    "max_scroll_attempts = 5\n",
    "\n",
    "# Stop getting data (reviews) if we reach end of the review page\n",
    "try:\n",
    "    last_position = get_current_scroll_position(driver)\n",
    "\n",
    "    # Loop which we will get the reviews\n",
    "    running = True\n",
    "    while running:\n",
    "        cards = driver.find_elements(By.CLASS_NAME, 'apphub_Card') # Can be found by 'inspect'\n",
    "\n",
    "        # Loop to check IDs and add the data (reviews) into our 'reviews' list for new/unseen IDs\n",
    "        for card in cards[-10:]:\n",
    "            steam_id = get_steam_id(card)\n",
    "            if steam_id in steam_ids_set: # If we have already added the review associated to the ID, then skip\n",
    "                continue\n",
    "            else:\n",
    "                review = scrape_review_data(card)\n",
    "                reviews.append(review)\n",
    "\n",
    "        # Check (and stop) when it reached the bottom of the review page\n",
    "        scroll_attempt = 0\n",
    "        while scroll_attempt < max_scroll_attempts:\n",
    "            scroll_to_bottom(driver)\n",
    "            current_position = get_current_scroll_position(driver)\n",
    "\n",
    "            if current_position == last_position:\n",
    "                scroll_attempt += 1\n",
    "                time.sleep(3)\n",
    "\n",
    "                if current_position >= 3:\n",
    "                    runnning = False\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                last_position = current_position\n",
    "                break\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a82b0-64d0-48fa-9e11-2a79660e1511",
   "metadata": {},
   "source": [
    "# Create DataFrame & Save As CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a2f0e-4425-4896-b35c-90af10c79368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT SCRAPED DATA INTO A DATAFRAME & DROP DUPLICATED ROWS\n",
    "\n",
    "# Create a DataFrame to insert our data\n",
    "df = pd.DataFrame(reviews, columns = ['ReviewText', 'RecommendedOrNot', 'ReviewLength', 'PlayHours', 'DatePosted'])\n",
    "\n",
    "# Drop the duplicated rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaadd3-05d2-40a3-8cb9-87f1a3c15b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our dataset into CSV file\n",
    "df.to_csv('wukong-dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
